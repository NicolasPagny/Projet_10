{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'recommander' from 'd:\\\\Formations\\\\Github\\\\Projet_10\\\\recommander.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "import recommander\n",
    "import importlib\n",
    "importlib.reload(recommander)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_PATH = \"datasets/\"\n",
    "ARTICLES_METADATA_PATH = DATASETS_PATH + \"articles_metadata.csv\"\n",
    "CLICKS_PATH = DATASETS_PATH + \"clicks/\"\n",
    "CLICKS_HOUR_CONCATENATED_PATH = DATASETS_PATH + \"clicks_hour_concatenated.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perc_fill_rate(datas: pd.DataFrame)-> float:\n",
    "    \"\"\"Calculer le taux de remplissage\n",
    "    \n",
    "    Parameters:\n",
    "    datas: Dataframe dont le taux de remplissage est à calculer\n",
    "\n",
    "    Returns:\n",
    "    float: taux de remplissage calculé\n",
    "    \"\"\"\n",
    "\n",
    "    return 100 - datas.isna().sum() / len(datas) * 100\n",
    "\n",
    "def make_title(texte:str):\n",
    "    \"\"\"Ecrit tout simplement un ###### texte #####\n",
    "    Cette fonction a été crée pour éviter de répéter les mêmes écritures de print\n",
    "\n",
    "    Parameters:\n",
    "    texte -- Texte à afficher\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n###### \" + texte + \" ######\\n\")\n",
    "\n",
    "def make_plot_dtypes(datas:pd.DataFrame):\n",
    "    \"\"\"Crée un camembert de répartition de types utilisés de la dataframe\n",
    "    \n",
    "    Parameters:\n",
    "    datas: Dataframe dont on veut calculer la répartition des types utilisées\n",
    "    \"\"\"\n",
    "\n",
    "    print(datas.dtypes.value_counts())\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.pie(datas.dtypes.value_counts().values,autopct=\"%1.2f%%\",labels=[str(types) for types in datas.dtypes.value_counts().index])\n",
    "    plt.title(\"Répartition des types dans le jeu de données.\")\n",
    "    plt.ylabel(\"Type des données\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def make_perc_missing_values_info(datas:pd.DataFrame, perc_missing_values_threshold: int = 50) -> sns.barplot:\n",
    "    \"\"\"Fonction qui affiche un diagramme en barres contenant le taux de remplissage pour chaque variable de la dataframe\n",
    "    \n",
    "    Parameters:\n",
    "    datas: Dataframe dont on désire afficher le taux de remplissage sous forme d'un diagramme en barres\n",
    "    perc_missing_values_threshold: Le seuil du pourcentage qui indique si une variable est exploitable ou non (par défaut : 50)\n",
    "    \n",
    "    Returns:\n",
    "    sns.barplot: contient l'objet de barplot\n",
    "    \"\"\"\n",
    "\n",
    "    # Calcul du taux de remplissage\n",
    "    perc_fill_rate_datas = perc_fill_rate(datas)\n",
    "    perc_fill_rate_datas = perc_fill_rate_datas.sort_values(ascending=False)\n",
    "\n",
    "    # Définition de la palette de couleurs en fonction du taux de remplissage\n",
    "    palette = [\"red\" if p < perc_missing_values_threshold else \"orange\" if p < 100 else \"green\" for p in perc_fill_rate_datas.values]\n",
    "\n",
    "    display(perc_fill_rate_datas.index)\n",
    "    display(perc_fill_rate_datas.values)\n",
    "\n",
    "    # Création d'un grpahique à barres pour le taux de remplissage\n",
    "    plt.figure(figsize=(25,5))\n",
    "    sns.barplot(x=perc_fill_rate_datas.index, y=perc_fill_rate_datas.values, hue=perc_fill_rate_datas.index, palette=palette)\n",
    "    plt.ylabel(\"Taux de remplissage\")\n",
    "    plt.xlabel(\"Variables\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"Taux de remplissage du fichier\")\n",
    "\n",
    "    # Mise en place d'une ligne rouge marquant le seuil décidé %\n",
    "    line_seuil = plt.axhline(y=perc_missing_values_threshold, color=\"red\", linestyle=\"--\", label=\"seuil \" + str(perc_missing_values_threshold) + \"%\")\n",
    "\n",
    "    # Création et paramétrage des légendes à afficher\n",
    "    red_patch = mpatches.Patch(color=\"red\", label=\"< \" + str(perc_missing_values_threshold) + \"%\")\n",
    "    orange_patch = mpatches.Patch(color=\"orange\", label= \"\" + str(perc_missing_values_threshold) + \"-]100%\")\n",
    "    green_patch = mpatches.Patch(color='green', label='100%')\n",
    "    plt.legend(handles=[line_seuil, red_patch, orange_patch, green_patch], title='Taux de remplissage', loc='upper right')\n",
    "    plt.show()\n",
    "\n",
    "    # Afficher une dataframe sur le taux de remplissage des variables\n",
    "    var_with_missing_values = perc_fill_rate_datas.loc[perc_fill_rate_datas < 100].to_frame()\n",
    "    var_with_missing_values = var_with_missing_values.reset_index()\n",
    "    var_with_missing_values = var_with_missing_values.rename(columns={\"index\": \"Variable\", 0: \"% Taux remplissage\"})\n",
    "    display(var_with_missing_values)\n",
    "\n",
    "def analyse_outlier(df: pd.DataFrame):\n",
    "    \"\"\"Analyse affiche un boxplot de chaque variable numérique afin d'analyser les outliers\n",
    "    \n",
    "    Parameters:\n",
    "    df: la dataframe dont on veut analyser les outliers\n",
    "    \"\"\"\n",
    "\n",
    "    # Ne sélectionner que les variables numériques\n",
    "    quantitatives = df.select_dtypes(include=[\"number\"])\n",
    "\n",
    "    make_title(\"Statistiques descriptives\")\n",
    "    display(quantitatives.describe())\n",
    "\n",
    "    # Afficher les boxplots de chaque variable\n",
    "    nb_var = len(quantitatives.columns)\n",
    "    nb_cols = 5\n",
    "    nb_rows = int(nb_var/nb_cols) + 1\n",
    "    fig, axes = plt.subplots(nb_rows, nb_cols, figsize=(25, nb_rows * 5))\n",
    "    for i, var in enumerate(quantitatives.columns):\n",
    "        if nb_rows > 1:\n",
    "            ax = axes[i // nb_cols, i % nb_cols]\n",
    "        else:\n",
    "            ax = axes[i // nb_cols]\n",
    "        sns.boxplot(x=quantitatives[var], ax=ax)\n",
    "\n",
    "    # Supprime les emplacements non utilisés\n",
    "    for i in range(nb_var, nb_rows * nb_cols):\n",
    "        fig.delaxes(axes.flatten()[i])\n",
    "\n",
    "    make_title(\"Boxplots des variables\")\n",
    "    plt.show()\n",
    "    \n",
    "def analyse_exploratoire_generique(datas: pd.DataFrame, perc_missing_values_threshold: int = 50, nb_index: int = 1):\n",
    "    \"\"\"Effectue une analyse exploratoire générique\n",
    "\n",
    "    Parameters:\n",
    "    datas: la dataframe sur laquelle on veut effectuer une analyse exploratoire générique\n",
    "    perc_missing_values_threshold: Le seuil du pourcentage de valeur manquant qui indique si une variable est exploitable ou non (par défaut: 50)\n",
    "    nb_index: index de début d'analyse de doublons, utilisé pour analyser les doublons en dehors des index\n",
    "    \"\"\"\n",
    "\n",
    "    # Présenter les informations générales\n",
    "    make_title(\"Informations générales\")\n",
    "    datas.info()\n",
    "\n",
    "    # Afficher la répartition des types dans le jeu de données\n",
    "    make_title(\"Répartition des types dans le dataset\")\n",
    "    make_plot_dtypes(datas)\n",
    "\n",
    "\n",
    "    # Afficher les 5 premières et derniè_res lignes du DataFrame\n",
    "    make_title(\"Les 5 premières et dernières lignes\")\n",
    "    head = datas.head()\n",
    "    tail = datas.tail()\n",
    "    display(head, tail)\n",
    "\n",
    "    # Afficher le nombre de valeurs uniques\n",
    "    make_title(\"Nombre de valeurs uniques\")\n",
    "    display(datas.nunique().to_frame().T)\n",
    "\n",
    "    # Afficher le nombre des doublons génériques\n",
    "    make_title(\"Doublons génériques (toutes les variables sont utilisées)\")\n",
    "    display(datas.duplicated().sum())\n",
    "\n",
    "    # Afficher le nombre des doublons sans l'index\n",
    "    make_title(\"Doublons sans l'index\")\n",
    "    display(datas[datas.columns[nb_index:]].duplicated().sum())\n",
    "\n",
    "    # Afficher les informations sur le taux de remplissage \n",
    "    make_title(\"Informations du taux de remplissage\")\n",
    "    make_perc_missing_values_info(datas, perc_missing_values_threshold)\n",
    "\n",
    "    # Afficher les analyses des variables numériques \n",
    "    analyse_outlier(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clicked_articles_user(user_id: int, clicks: pd.DataFrame):\n",
    "    \"\"\"obtenir les articles cliqués par un utilisateur donné\n",
    "    \n",
    "    Parameters:\n",
    "    user_id: l'identifiant de l'utilisateur\n",
    "    clicks: la dataframe contenant les clics\n",
    "    \"\"\"\n",
    "\n",
    "    # Sélectionner les articles cliqués par l'utilisateur\n",
    "    articles_user = clicks[clicks[\"user_id\"] == user_id]\n",
    "    articles_user = articles_user[[\"click_article_id\", \"click_timestamp\"]]\n",
    "\n",
    "    return articles_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_clicked_articles_user(user_id: int, clicks: pd.DataFrame):\n",
    "    \"\"\"Obtenir le dernier article cliqué par un utilisateur\n",
    "\n",
    "    Parameters:\n",
    "    user_id: l'identifiant de l'utilisateur\n",
    "    clicks: la dataframe contenant les clics\n",
    "    \"\"\"\n",
    "\n",
    "    articles_user = get_clicked_articles_user(user_id, clicks)\n",
    "    last_article = articles_user[articles_user[\"click_timestamp\"] == articles_user[\"click_timestamp\"].max()]\n",
    "\n",
    "    return last_article\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1, vector2):\n",
    "    \"\"\"Calculer la similarité cosinus entre les articles\n",
    "    \"\"\"\n",
    "\n",
    "    similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_most_similar_articles(article_id, articles_embeddings):\n",
    "    \"\"\"Trouver les 5 articles les plus similaires à un article donné\n",
    "    \"\"\"\n",
    "\n",
    "    article_embedding = articles_embeddings[article_id]\n",
    "    similarities = {}\n",
    "    for id, embedding in enumerate(articles_embeddings):\n",
    "        similarities[id] = cosine_similarity(article_embedding, embedding)\n",
    "    similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "    return similarities[1:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = pd.read_csv(ARTICLES_METADATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(CLICKS_HOUR_CONCATENATED_PATH):\n",
    "    df_clicks_hour = pd.read_csv(CLICKS_HOUR_CONCATENATED_PATH)\n",
    "else:\n",
    "    df_clicks_hour = pd.DataFrame()\n",
    "\n",
    "    clicks_hour_files = os.listdir(CLICKS_PATH)\n",
    "    for file in clicks_hour_files:\n",
    "        df_clicks_hour = pd.concat([df_clicks_hour, pd.read_csv(CLICKS_PATH + file)], ignore_index=True)\n",
    "    \n",
    "    df_clicks_hour.to_csv(CLICKS_HOUR_CONCATENATED_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATASETS_PATH + \"articles_embeddings.pickle\", \"rb\") as f:\n",
    "    np_embedding_articles = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "click_article_id\n",
       "160974    37213\n",
       "272143    28943\n",
       "336221    23851\n",
       "234698    23499\n",
       "123909    23122\n",
       "336223    21855\n",
       "96210     21577\n",
       "162655    21062\n",
       "183176    20303\n",
       "168623    19526\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommander.most_popular_articles(df_clicks_hour, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clicks_ar = df_clicks_hour.groupby(\"click_article_id\").size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clicks_us = df_clicks_hour.groupby(\"user_id\").size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_pas = [nb_clicks_ar[nb_clicks_ar > pas].size for pas in range(0, int(nb_clicks_ar.size / 5), 5)]\n",
    "us_pas = [nb_clicks_us[nb_clicks_us > pas].size for pas in range(10, int(nb_clicks_us.size / 5), 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultat = np.outer(ar_pas, us_pas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 100000000\n",
    "ecarts = np.abs(resultat - target)\n",
    "indice_min = np.unravel_index(np.argmin(ecarts, axis=None), ecarts.shape)\n",
    "\n",
    "valeur_proche = resultat[indice_min]\n",
    "indice_ar = indice_min[0]\n",
    "indice_us = indice_min[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99628099\n",
      "270\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(valeur_proche)\n",
    "print(indice_ar * 5)\n",
    "print(indice_us * 5 + 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1289"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clicks_ar[nb_clicks_ar > 270].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77291"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clicks_us[nb_clicks_us > 10].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_limit_ar  = nb_clicks_ar[nb_clicks_ar > 270]\n",
    "test_limit_us = nb_clicks_us[nb_clicks_us > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31748"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clicks_hour[df_clicks_hour[\"user_id\"].isin(test_limit_us.index)][\"click_article_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "limited_articles = df_clicks_hour[df_clicks_hour[\"click_article_id\"].isin(test_limit_ar.index) & df_clicks_hour[\"user_id\"].isin(test_limit_us.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "click_article_id\n",
       "2647      0.205250\n",
       "3394      0.202874\n",
       "4907      0.204280\n",
       "5252      0.204077\n",
       "5292      0.201551\n",
       "            ...   \n",
       "362322    0.202936\n",
       "362914    0.208081\n",
       "363173    0.203366\n",
       "363910    0.200998\n",
       "363916    0.201781\n",
       "Name: 5, Length: 1289, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(recommander)\n",
    "recommander.preds_svds_user(5, limited_articles, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1289"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limited_articles[\"click_article_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "limited_embedding_articles = np_embedding_articles[limited_articles[\"click_article_id\"].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(recommander)\n",
    "cb = recommander.best_cosine_similar_articles_per_user(5, limited_articles, np_embedding_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151770    0.900357\n",
       "161332    0.872341\n",
       "160700    0.860313\n",
       "160233    0.854030\n",
       "155009    0.850001\n",
       "dtype: float32"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('best cosine similar', 87278    0.871122\n",
      "86143    0.869657\n",
      "87676    0.865084\n",
      "87030    0.864888\n",
      "87427    0.864443\n",
      "dtype: float32)\n",
      "('hybrid', click_article_id\n",
      "123909    0.481104\n",
      "236613    0.433263\n",
      "272660    0.373180\n",
      "235847    0.345744\n",
      "272143    0.325853\n",
      "dtype: float64)\n",
      "('best cosine similar', 205848    0.938932\n",
      "206549    0.934476\n",
      "209266    0.933231\n",
      "206618    0.931547\n",
      "206655    0.927882\n",
      "dtype: float32)\n",
      "('hybrid', click_article_id\n",
      "140528    0.419606\n",
      "124749    0.382978\n",
      "123909    0.379492\n",
      "199198    0.374778\n",
      "225019    0.360653\n",
      "dtype: float64)\n",
      "('best cosine similar', 268529    0.937614\n",
      "272709    0.911025\n",
      "267850    0.910974\n",
      "270215    0.908559\n",
      "269732    0.908437\n",
      "dtype: float32)\n",
      "('hybrid', click_article_id\n",
      "156355    0.424460\n",
      "160974    0.406963\n",
      "157798    0.402451\n",
      "161801    0.401649\n",
      "156700    0.369704\n",
      "dtype: float64)\n",
      "('hybrid', click_article_id\n",
      "160974    0.554023\n",
      "234698    0.392394\n",
      "207485    0.345176\n",
      "235854    0.322891\n",
      "233717    0.321837\n",
      "dtype: float64)\n",
      "('hybrid', click_article_id\n",
      "158046    0.233359\n",
      "162725    0.223654\n",
      "199411    0.207055\n",
      "237807    0.205779\n",
      "31520     0.147193\n",
      "dtype: float64)\n",
      "('hybrid', click_article_id\n",
      "207603    0.506246\n",
      "123909    0.448893\n",
      "29953     0.314616\n",
      "30389     0.275869\n",
      "206785    0.266911\n",
      "dtype: float64)\n",
      "('best cosine similar', 293259    0.933796\n",
      "291636    0.931363\n",
      "292477    0.930610\n",
      "347220    0.929196\n",
      "346662    0.928483\n",
      "dtype: float32)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(recommander)\n",
    "for i in range(0, 10):\n",
    "    hybrid_articles = recommander.hybrid_recommander(i, df_clicks_hour, np_embedding_articles, 15)\n",
    "    print(hybrid_articles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
